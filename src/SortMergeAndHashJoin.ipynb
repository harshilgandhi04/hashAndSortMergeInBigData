{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3adb12f1-a85d-4294-9d2c-4f144d297f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "import time\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79e557c0-8eda-4a03-a82e-53cef4a6de89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch subject,object,property\n",
    "def pre_process_data(df):\n",
    "    \n",
    "    df[0] = df[0].split(\":\")[1].strip()\n",
    "    df[1] = df[1].split(\":\")[1].strip()\n",
    "    df[2] = df[2].split(\":\")[1][:-1].strip() if len(df[2].split(\":\")) > 1 else df[2][:-1].strip()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b6cc870-3094-490a-a529-82438f6b5802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read 100k.txt into a pandas dataframe\n",
    "raw_df = pd.read_csv(\"100k.txt\", \n",
    "                     header = None, \n",
    "                     sep=\"\\t\", \n",
    "                     quotechar='\"', \n",
    "                     skipinitialspace=True, \n",
    "                     names=['subject','property','object'])\n",
    "\n",
    "raw_df = raw_df.apply(pre_process_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7159ac53-a7fd-4a78-9656-28101bf61fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_df is a dictionary of dataframes with \n",
    "# key: property name, value: dataframe with subject, property and object for a given property\n",
    "dict_df = dict(tuple(raw_df.groupby('property', as_index=False)))\n",
    "\n",
    "# remove \"property\" column from every dataframe is dictionary dfs\n",
    "for key in dict_df:\n",
    "    dict_df[key] = dict_df[key].drop(\"property\", axis=1)\n",
    "    dict_df[key].reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "322d5940-7bc7-4968-aec5-8b5ac9bdd2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortMergeJoin(df1, key1, df2, key2):\n",
    "    \n",
    "    #Perform Sorting based on keys\n",
    "    sort_df1_On_key1 = df1.sort_values(by=key1, ascending=True)\n",
    "    sort_df2_On_key2 = df2.sort_values(by=key2, ascending=True)\n",
    "    \n",
    "    results_df = pd.merge(sort_df1_On_key1, sort_df2_On_key2, left_on=key1, right_on=key2, how='inner')\n",
    "\n",
    "    return results_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6e277f2-3f02-47c7-908e-ec144ec69c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4056/159088401.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sortMergeJoin_QueryResult_df.rename(columns = {'subject_x_x':'follows.subject',\n"
     ]
    }
   ],
   "source": [
    "# Sort Merge Join Results\n",
    "start_time = time.time()\n",
    "\n",
    "followsObj_friendOfSubj_smj_df = sortMergeJoin(\n",
    "    dict_df[\"follows\"],\"object\",\n",
    "    dict_df[\"friendOf\"],\"subject\")\n",
    "\n",
    "likesObj_hasReviewSubj_smj_df = sortMergeJoin(\n",
    "    dict_df[\"likes\"],\"object\",\n",
    "    dict_df[\"hasReview\"],\"subject\")\n",
    "\n",
    "friendsOfObj_likesSubj_smj_df = sortMergeJoin(\n",
    "    followsObj_friendOfSubj_smj_df,\"object_y\",\n",
    "    likesObj_hasReviewSubj_smj_df,\"subject_x\")\n",
    "\n",
    "sortMergeJoin_QueryResult_df = friendsOfObj_likesSubj_smj_df[[\"subject_x_x\",\n",
    "                                     \"object_x_x\",\n",
    "                                     \"object_y_x\",\n",
    "                                     \"object_x_y\",\n",
    "                                     \"object_y_y\"]]\n",
    "\n",
    "sortMergeJoin_QueryResult_df.rename(columns = {'subject_x_x':'follows.subject',\n",
    "                                       'object_x_x':'follows.object',\n",
    "                                       'object_y_x':'friendOf.object',\n",
    "                                       'object_x_y':'likes.object',\n",
    "                                       'object_y_y':' hasReview.object'}, inplace = True)\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413feb95-67ae-4c1e-b923-ce92b658260b",
   "metadata": {},
   "source": [
    "## Sort Merge Join Time Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "863967bd-5740-4f61-85f2-6233dbd2cfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for Sort merge Join: 7.9176695346832275 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Execution time for Sort merge Join: %s seconds\" %(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "effca88f-c555-4fe3-8a4e-775e6700abea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashJoin(df1, key1, df2, key2):\n",
    "    \n",
    "    df1[\"hash_key\"] = df1[key1].apply(hash)\n",
    "    df2[\"hash_key\"] = df2[key2].apply(hash)\n",
    "    \n",
    "    df1_partitions = dict(tuple(df1.groupby('hash_key')))\n",
    "    for key in df1_partitions:\n",
    "        df1_partitions[key].reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    dictKeys = df1_partitions.keys()\n",
    "    resultAsList = []\n",
    "    \n",
    "    for i in range(len(df2)):\n",
    "        if (df2.iloc[i]['hash_key']) in dictKeys:\n",
    "            key = df2.iloc[i]['hash_key']\n",
    "            joinRow = df2.iloc[[i]]\n",
    "            joinedRow = pd.merge(df1_partitions[key],joinRow, on='hash_key',  how='left')\n",
    "            resultAsList.append(joinedRow.to_dict('list'))\n",
    "    \n",
    "    listOfJoinedPartitions = []\n",
    "    for dictionary in resultAsList:\n",
    "        listOfJoinedPartitions.append(pd.DataFrame(dictionary))\n",
    "    \n",
    "    finalDf = pd.concat(listOfJoinedPartitions)\n",
    "    finalDf = finalDf.drop('hash_key',axis=1)\n",
    "    \n",
    "    return finalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c8f90b3-e17b-4f38-a022-0de7d7692032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4056/325213909.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hashJoin_QueryResult_df.rename(columns = {'subject_x_x': 'follows.subject',\n"
     ]
    }
   ],
   "source": [
    "#Hash Join Results\n",
    "start_time = time.time()\n",
    "\n",
    "followsObj_friendOfSubj_hj_df = hashJoin(\n",
    "    dict_df['follows'], 'object',\n",
    "    dict_df['friendOf'], 'subject')\n",
    "\n",
    "likesObj_hasReviewSubj_hj_df = hashJoin(\n",
    "    dict_df['likes'], 'object',\n",
    "    dict_df['hasReview'], 'subject')\n",
    "\n",
    "friendsOfObj_likesSubj_hj_df = hashJoin(\n",
    "    followsObj_friendOfSubj_hj_df, 'object_y',\n",
    "    likesObj_hasReviewSubj_hj_df, 'subject_x')\n",
    "\n",
    "hashJoin_QueryResult_df = friendsOfObj_likesSubj_hj_df[[\"subject_x_x\",\n",
    "                                     \"object_x_x\",\n",
    "                                     \"object_y_x\",\n",
    "                                     \"object_x_y\",\n",
    "                                     \"object_y_y\"]]\n",
    "\n",
    "hashJoin_QueryResult_df.rename(columns = {'subject_x_x': 'follows.subject',\n",
    "                                          'object_x_x': 'follows.object',\n",
    "                                          'object_y_x': 'friendOf.object',\n",
    "                                          'object_x_y': 'likes.object',\n",
    "                                          'object_y_y': 'hasReview.object'}, inplace = True)\n",
    "                               \n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7271de4d-64a4-46dc-96da-48b2a3579ab0",
   "metadata": {},
   "source": [
    "## Hash Join Time Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a73ee80-4211-465f-97c6-e739acb43960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for Hash Join: 196.18216705322266 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Execution time for Hash Join: %s seconds\" %(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7407cfe-54e8-47e1-8257-c14dc3da7ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def improvedHashJoin(df1, key1, df2, key2):\n",
    "    \n",
    "    df1[\"hash_key\"] = df1[key1].apply(hash)\n",
    "    df2[\"hash_key\"] = df2[key2].apply(hash)\n",
    "    \n",
    "    df1_partitions = dict(tuple(df1.groupby('hash_key')))\n",
    "    for key in df1_partitions:\n",
    "        df1_partitions[key].reset_index(drop = True, inplace = True)\n",
    "\n",
    "    df2_partitions = dict(tuple(df2.groupby('hash_key')))\n",
    "    for key in df2_partitions:\n",
    "        df2_partitions[key].reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    resultAsList = []\n",
    "    for key_2 in df2_partitions:\n",
    "        for key_1 in df1_partitions:\n",
    "            if key_1 == key_2:\n",
    "                joinedPartitions = pd.merge(df1_partitions[key_1],df2_partitions[key_2], on='hash_key',  how='left')\n",
    "                resultAsList.append(joinedPartitions.to_dict('list'))\n",
    "    \n",
    "    listOfJoinedPartitions = []\n",
    "    for dictionary in resultAsList:\n",
    "        listOfJoinedPartitions.append(pd.DataFrame(dictionary))\n",
    "    \n",
    "    finalDf = pd.concat(listOfJoinedPartitions)\n",
    "    finalDf = finalDf.drop('hash_key',axis=1)\n",
    "    return finalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bc3d207-0d31-4658-9226-c26bad5d233d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4056/1294638882.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  improvedHashJoin_QueryResult_df.rename(columns = {'subject_x_x': 'follows.subject',\n"
     ]
    }
   ],
   "source": [
    "#Improved Hash Join Results\n",
    "start_time = time.time()\n",
    "\n",
    "followsObj_friendOfSubj_ihj_df = improvedHashJoin(\n",
    "    dict_df['follows'], 'object',\n",
    "    dict_df['friendOf'], 'subject')\n",
    "\n",
    "likesObj_hasReviewSubj_ihj_df = improvedHashJoin(\n",
    "    dict_df['likes'], 'object',\n",
    "    dict_df['hasReview'], 'subject')\n",
    "\n",
    "friendsOfObj_likesSubj_ihj_df = improvedHashJoin(\n",
    "    followsObj_friendOfSubj_ihj_df, 'object_y',\n",
    "    likesObj_hasReviewSubj_ihj_df, 'subject_x')\n",
    "\n",
    "improvedHashJoin_QueryResult_df = friendsOfObj_likesSubj_ihj_df[[\"subject_x_x\",\n",
    "                                     \"object_x_x\",\n",
    "                                     \"object_y_x\",\n",
    "                                     \"object_x_y\",\n",
    "                                     \"object_y_y\"]]\n",
    "\n",
    "improvedHashJoin_QueryResult_df.rename(columns = {'subject_x_x': 'follows.subject',\n",
    "                                          'object_x_x': 'follows.object',\n",
    "                                          'object_y_x': 'friendOf.object',\n",
    "                                          'object_x_y': 'likes.object',\n",
    "                                          'object_y_y': 'hasReview.object'}, inplace = True)\n",
    "                               \n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3ff0cd-db43-42ae-a6a0-b3045e46960d",
   "metadata": {},
   "source": [
    "## Improved Hash Join Time Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03078489-26d0-4727-9b71-a7f0f5213178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for Improved Hash Join: 27.514806509017944 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Execution time for Improved Hash Join: %s seconds\" %(end_time - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
